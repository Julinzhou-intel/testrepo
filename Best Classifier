#importing necessary libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as pyp
import sklearn.preprocessing as preprocessing
!wget -O loan_train.csv https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/FinalModule_Coursera/data/loan_train.csv
--2022-06-25 15:49:15--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/FinalModule_Coursera/data/loan_train.csv
Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104
Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 23101 (23K) [text/csv]
Saving to: ‘loan_train.csv’

loan_train.csv      100%[===================>]  22.56K  --.-KB/s    in 0s      

2022-06-25 15:49:16 (97.2 MB/s) - ‘loan_train.csv’ saved [23101/23101]

#loading the dataset
dataframe=pd.read_csv('loan_train.csv')
print(dataframe.head())
   Unnamed: 0  Unnamed: 0.1 loan_status  Principal  terms effective_date  \
0           0             0     PAIDOFF       1000     30       9/8/2016   
1           2             2     PAIDOFF       1000     30       9/8/2016   
2           3             3     PAIDOFF       1000     15       9/8/2016   
3           4             4     PAIDOFF       1000     30       9/9/2016   
4           6             6     PAIDOFF       1000     30       9/9/2016   

    due_date  age             education  Gender  
0  10/7/2016   45  High School or Below    male  
1  10/7/2016   33              Bechalor  female  
2  9/22/2016   27               college    male  
3  10/8/2016   28               college  female  
4  10/8/2016   29               college    male  
#checking the columns names
print(dataframe.columns)
Index(['Unnamed: 0', 'Unnamed: 0.1', 'loan_status', 'Principal', 'terms',
       'effective_date', 'due_date', 'age', 'education', 'Gender'],
      dtype='object')
#cleansing the data
#1.dropping column unnamed since it is just the index
dataframe.drop(columns=['Unnamed: 0.1','Unnamed: 0.1'])
dataframe=dataframe.iloc[:,2:]
print(dataframe.columns)
Index(['loan_status', 'Principal', 'terms', 'effective_date', 'due_date',
       'age', 'education', 'Gender'],
      dtype='object')
#checking number of unique values in each column
for col in dataframe.columns:
    print(col,'=',dataframe[col].nunique(),' unique values')
loan_status = 2  unique values
Principal = 5  unique values
terms = 3  unique values
effective_date = 7  unique values
due_date = 23  unique values
age = 32  unique values
education = 4  unique values
Gender = 2  unique values
as seen loan_status and gender have binary values

print(dataframe['loan_status'].unique())
print(dataframe['Gender'].unique())
['PAIDOFF' 'COLLECTION']
['male' 'female']
#changing the two columns to binary
dataframe['loan_status']=np.where(dataframe['loan_status']=='PAIDOFF',1,0)
dataframe['Gender']=np.where(dataframe['Gender']=='male',1,0)
print(dataframe.head())
   loan_status  Principal  terms effective_date   due_date  age  \
0            1       1000     30       9/8/2016  10/7/2016   45   
1            1       1000     30       9/8/2016  10/7/2016   33   
2            1       1000     15       9/8/2016  9/22/2016   27   
3            1       1000     30       9/9/2016  10/8/2016   28   
4            1       1000     30       9/9/2016  10/8/2016   29   

              education  Gender  
0  High School or Below       1  
1              Bechalor       0  
2               college       1  
3               college       0  
4               college       1  
loan_status and gender hve become binary now to find the time limit of someones date

dataframe.dtypes#finding the datatype of eaach column
loan_status        int64
Principal          int64
terms              int64
effective_date    object
due_date          object
age                int64
education         object
Gender             int64
dtype: object
#effective_date and due_date are strings
#convert to datetime
dataframe[['due_date','effective_date']]=dataframe[['due_date','effective_date']].apply(pd.to_datetime)
dataframe.dtypes
loan_status                int64
Principal                  int64
terms                      int64
effective_date    datetime64[ns]
due_date          datetime64[ns]
age                        int64
education                 object
Gender                     int64
dtype: object
#add a column called difference to the dataset that is the time allowed for the loan
dataframe['difference']=(dataframe['due_date']-dataframe['effective_date'])/np.timedelta64(1,'D')
#then drop the two columns
dataframe.drop(dataframe.columns[[3,4]],axis=1,inplace=True)
print(dataframe.head())
   loan_status  Principal  terms  age             education  Gender  \
0            1       1000     30   45  High School or Below       1   
1            1       1000     30   33              Bechalor       0   
2            1       1000     15   27               college       1   
3            1       1000     30   28               college       0   
4            1       1000     30   29               college       1   

   difference  
0        29.0  
1        29.0  
2        14.0  
3        29.0  
4        29.0  
dataframe=pd.get_dummies(dataframe)
dataframe.head()
loan_status	Principal	terms	age	Gender	difference	education_Bechalor	education_High School or Below	education_Master or Above	education_college
0	1	1000	30	45	1	29.0	0	1	0	0
1	1	1000	30	33	0	29.0	1	0	0	0
2	1	1000	15	27	1	14.0	0	0	0	1
3	1	1000	30	28	0	29.0	0	0	0	1
4	1	1000	30	29	1	29.0	0	0	0	1
#setting the target which is loan status
y=dataframe['loan_status'].values
x=(dataframe.iloc[:,1].values).astype('float32')
print(x.shape,y.shape)
(346,) (346,)
x=x.reshape(-1,1)
#preprocessing the data
x=preprocessing.StandardScaler().fit(x).transform(x.astype('float32'))
#split the data set
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=4)
#using knn and its respective evaluation
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import f1_score,jaccard_score
knn_model=KNeighborsClassifier(n_neighbors=5)
knn_model.fit(x_train,y_train)
print('Jaccard:')
print('Training accuracy:',jaccard_score(y_train,knn_model.predict(x_train),pos_label=1))
print('out of sample accuracy:',jaccard_score(y_test,knn_model.predict(x_test),pos_label=1))
print('F1_score:')
print('Training accuracy:',f1_score(y_train,knn_model.predict(x_train),average='weighted'))
print('Out of sample accuracy:',f1_score(y_test,knn_model.predict(x_test),average='weighted'))
Jaccard:
Training accuracy: 0.7427536231884058
out of sample accuracy: 0.7857142857142857
F1_score:
Training accuracy: 0.6331163939859591
Out of sample accuracy: 0.6914285714285714
#decision tree and respective evaluation
from sklearn.tree import DecisionTreeClassifier
tree_model=DecisionTreeClassifier(criterion='entropy',max_depth=4)
tree_model.fit(x_train,y_train)
print('Jaccard:')
print('Training accuracy:',jaccard_score(y_train,tree_model.predict(x_train),pos_label=1))
print('out of sample accuracy:',jaccard_score(y_test,tree_model.predict(x_test),pos_label=1))
print('F1_score:')
print('Training accuracy:',f1_score(y_train,tree_model.predict(x_train),average='weighted'))
print('Out of sample accuracy:',f1_score(y_test,tree_model.predict(x_test),average='weighted'))
Jaccard:
Training accuracy: 0.7427536231884058
out of sample accuracy: 0.7857142857142857
F1_score:
Training accuracy: 0.6331163939859591
Out of sample accuracy: 0.6914285714285714
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import log_loss
logistic_model=LogisticRegression(C=0.01,solver='liblinear')
logistic_model.fit(x_train,y_train)
print('Jaccard:')
print('Training accuracy:',jaccard_score(y_train,logistic_model.predict(x_train),pos_label=1))
print('out of sample accuracy:',jaccard_score(y_test,logistic_model.predict(x_test),pos_label=1))
print('F1_score:')
print('Training accuracy:',f1_score(y_train,logistic_model.predict(x_train),average='weighted'))
print('Out of sample accuracy:',f1_score(y_test,logistic_model.predict(x_test),average='weighted'))
print('log loss:')
print('Training accuracy:',log_loss(y_train,logistic_model.predict_proba(x_train)))
print('Out of sample accuracy:',f1_score(y_test,logistic_model.predict_proba(x_test)))
Jaccard:
Training accuracy: 0.7427536231884058
out of sample accuracy: 0.7857142857142857
F1_score:
Training accuracy: 0.6331163939859591
Out of sample accuracy: 0.6914285714285714
log loss:
Training accuracy: 0.6146507279934235
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
/tmp/wsuser/ipykernel_165/1566626473.py in <module>
     11 print('log loss:')
     12 print('Training accuracy:',log_loss(y_train,logistic_model.predict_proba(x_train)))
---> 13 print('Out of sample accuracy:',f1_score(y_test,logistic_model.predict_proba(x_test)))
     14 

/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py in f1_score(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)
   1121     modified with ``zero_division``.
   1122     """
-> 1123     return fbeta_score(
   1124         y_true,
   1125         y_pred,

/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py in fbeta_score(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)
   1259     """
   1260 
-> 1261     _, _, f, _ = precision_recall_fscore_support(
   1262         y_true,
   1263         y_pred,

/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py in precision_recall_fscore_support(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)
   1542     if beta < 0:
   1543         raise ValueError("beta should be >=0 in the F-beta score")
-> 1544     labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
   1545 
   1546     # Calculate tp_sum, pred_sum, true_sum ###

/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py in _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
   1346         raise ValueError("average has to be one of " + str(average_options))
   1347 
-> 1348     y_type, y_true, y_pred = _check_targets(y_true, y_pred)
   1349     # Convert to Python primitive type to avoid NumPy type / Python str
   1350     # comparison. See https://github.com/numpy/numpy/issues/6784

/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/sklearn/metrics/_classification.py in _check_targets(y_true, y_pred)
     91 
     92     if len(y_type) > 1:
---> 93         raise ValueError(
     94             "Classification metrics can't handle a mix of {0} and {1} targets".format(
     95                 type_true, type_pred

ValueError: Classification metrics can't handle a mix of binary and continuous-multioutput targets
#support vector machine and respective evaluation
from sklearn import svm
svm_model=svm.SVC(kernel='rbf')
svm_model.fit(x_train,y_train)
print('Jaccard:')
print('Training accuracy:',jaccard_score(y_train,svm_model.predict(x_train),pos_label=1))
print('out of sample accuracy:',jaccard_score(y_test,svm_model.predict(x_test),pos_label=1))
print('F1_score:')
print('Training accuracy:',f1_score(y_train,svm_model.predict(x_train),average='weighted'))
print('Out of sample accuracy:',f1_score(y_test,svm_model.predict(x_test),average='weighted'))
Jaccard:
Training accuracy: 0.7427536231884058
out of sample accuracy: 0.7857142857142857
F1_score:
Training accuracy: 0.6331163939859591
Out of sample accuracy: 0.6914285714285714
